%matplotlib inline

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import norm
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances
from sklearn.datasets import make_blobs
import time

# The $k$-means algorithm

def kmeans_init_centers(X, k):
    """
    Initialize centers for K-means algorithm by randomly choosing k points from the dataset.

    Arguments:
    X -- input data.
    k -- number of centroids.

    Return:
    c -- initial centers.
    """
    # TODO 1: randomly pick k rows of X as initial centers
    random_indices = np.random.choice(len(X), k, replace=False)
    c = X[random_indices]
    return c

def kmeans_assign_labels(X, centroids):
    """
    Assign a label for each data point. Each data point is assigned to its nearest centroid, based on the squared Euclidean distance.

    Arguments:
    X         -- input data.
    centroids -- centroids.

    Return:
    labels    -- assigned label for each data point.
    """
    # TODO 2: compute the distance matrix between each data point and the set of centroids
    distance_matrix = pairwise_distances(X, centroids, metric='euclidean')

    # TODO 3: assign each data point to the closest centroid
    labels = np.argmin(distance_matrix, axis=1)
    return labels

def kmeans_update_centers(X, labels, k):
    """
    Update the new centroids by taking the mean of all data points assigned to their centroid's cluster.

    Arguments:
    X      -- input data.
    labels -- label for each data point.
    k      -- number of clusters.

    Return:
    centroids -- updated centroids.
    """
    centroids = np.empty((k, X.shape[1]))
    for idx in range(k):
        # select all data points that belong to cluster i and compute the mean of these data points (each feature individually)
        # this will be our new cluster centroids
        centroids[idx] = np.mean(X[labels == idx], axis=0)
    return centroids

def isConverged(c1, c2):
    """
    Check whether or not convergence is reached by checking the current centroids and the previous centroids are equal.

    Arguments:
    c1 -- current centroids.
    c2 -- previous centroids.

    Return:
    True  -- the current centroids and the previous centroids are equal.
    False -- otherwise.
    """
    # TODO 5: Check if c1 and c2 are equal, return True if yes, False otherwise
    return np.array_equal(c1, c2)

def kmeans(X, k, maxiter, seed=None):
    """
    An implementation of the K-means algorithm alternating between two steps:
    1. Assignment step: observations are associated with the closest centroid (squared Euclidean distance).
    2. Update step: new centroids are computed based on the new points associated with each centroid.
    K-means algorithm will end before maxIter if the current centroid and the previous centroids are the same.

    *NOTE: This is a baseline version of the K-means algorithm.

    Arguments:
    X         -- data.
    k         -- number of expected clusters.
    maxiter   -- number of iterations that K-means should run.
    seed      -- integer starting value for the seed() method.

    Return:
    cluster_assignment -- cluster label of data point.
    new_centroids      -- updated centroids.
    centroids_Hist     -- a list containing the centroid's position for each iteration.
    """
    if seed is not None:
        np.random.seed(seed)

    # Initialize centroids
    init_centroids = kmeans_init_centers(X, k)

    # History vectors
    centroids_Hist = [init_centroids]
    old_centroids = init_centroids

    for itr in range(maxiter):
        # ---------------
        # ASSIGNMENT STEP
        # ---------------
        cluster_assignment = kmeans_assign_labels(X, old_centroids)

        # UPDATE STEP
        new_centroids = kmeans_update_centers(X, cluster_assignment, k)

        # STOP CONDITION
        if isConverged(new_centroids, old_centroids):
            break

        old_centroids = new_centroids
        centroids_Hist.append(new_centroids)

    return cluster_assignment, new_centroids, np.array(centroids_Hist)

def plot_kmeans(data, labels, centroids, centroids_Hist=None):
    '''
    Plot the clustered data of Kmeans algorithm.
    
    Arguments:
    data             --- the input data.
    labels           --- label for each data point applied Kmeans.
    centroids        --- centers for each cluster applied Kmeans.
    centroids_Hist   --- a list contains the centroid's position for each iteration.
    
    '''
    
    # figure configuration
    plt.rcParams['figure.figsize'] = 15, 6 
    plt.rcParams['font.size'] = 12
    xmin = min(data[:, 0])
    xmax = max(data[:, 0])
    ymin = min(data[:, 1])
    ymax = max(data[:, 1])
    
    plt.ylim(ymin - 1, ymax + 1)
    plt.xlim(xmin - 1, xmax + 1)
    plt.gca().set_aspect('equal')
    
    # scatter plot
    plt.scatter(data[:,0], data[:,1], c=labels)
    plt.scatter(centroids[:,0], centroids[:,1], c='r', marker='^', s=200)
    if centroids_Hist is not None:
        for i in range(len(centroids)):
            plt.plot(centroids_Hist[:, i, 0], centroids_Hist[:, i, 1], c='b', marker=">")

def main():
    # Synthetic data generation
    X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=0.6)

    # Parameter configuration
    Nb_cluster = 4
    numIterations = 100
    data = X

    # Run K-means algorithm for two cases with different initial centroids
    for i in range(1, 3):
        # Apply K-means algorithm to the given dataset
        labels, centers, centers_Hist = kmeans(data, Nb_cluster, numIterations, seed=i)
        
        # Print the number of data points that belong to each cluster
        for cluster_index in range(Nb_cluster):
            num_points_in_cluster = np.sum(labels == cluster_index)
            print(f"Number of data points in Cluster {cluster_index + 1}: {num_points_in_cluster}")

        # Plot the clustered dataset
        plt.subplot(1, 2, i)
        plt.title(f'Case {i}')
        plot_kmeans(data, labels, centers, centers_Hist)
        plt.show()

    # TODO 6: implement K-means algorithm using sklearn
    skl_kmeans = KMeans(n_clusters=Nb_cluster, random_state=0)
    skl_labels = skl_kmeans.fit_predict(data)
    skl_centers = skl_kmeans.cluster_centers_

    # Print the centers found by scikit-learn
    print('Centers found by scikit-learn:\n', skl_centers)

    # Plot the clustered dataset using the same function as in Question 1
    plot_kmeans(data, skl_labels, skl_centers)

if __name__ == "__main__":
    main()
